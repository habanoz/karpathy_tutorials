# Implemenations for Lectures by Andrej Karpathy

## Let's build GPT from scratch

[Lecture:Let's build GPT from scratch](https://www.youtube.com/watch?v=kCc8FmEb1nY)

[Reference Code: nanogpt-lecture](https://github.com/karpathy/ng-video-lecture)

Develop a tiny GPT2 model with 10M parameters.

[My Code](lets_build_gtp/7_final.py)

## Let's reproduce GPT-2 (124M)

[Lecture:Let's reproduce GPT-2 (124M)](https://www.youtube.com/watch?v=l8pRSuU81PU)

[Reference Code: Nano-gpt](https://github.com/karpathy/build-nanogpt)

Train a 124M parameters GPT2 model from scratch. Apply optimizations. Use Torch DDP for distributed training.

[MY Code](build_nano_gpt/train_gpt2.py)
